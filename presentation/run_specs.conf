# List the RunSpecs that we want to display on the website in this file.
# A RunSpec specifies how to do a single run, which gets a scenario, adapts it, and computes a list of metrics.
#
# RunSpecs are unique. Mark the RunSpec with either READY or WIP (work in progress).
# For READY RunSpecs, we evaluate and generate metrics.
# For WIP RunSpecs, we just estimate token usage.

"copyright:pilot_study=true" : {status: "READY"}
"lpm:difficulty=easy" : {status: "READY"}
"lpm:difficulty=hard" : {status: "READY"}

# TODO: should we include all of the 57 subjects available in MMLU?
"mmlu:subject=abstract_algebra" : {status: "READY"}
"mmlu:subject=anatomy" : {status: "READY"}
"mmlu:subject=college_chemistry" : {status: "READY"}
"mmlu:subject=computer_security" : {status: "READY"}
"mmlu:subject=econometrics" : {status: "READY"}
"mmlu:subject=global_facts" : {status: "READY"}
"mmlu:subject=jurisprudence" : {status: "READY"}
"mmlu:subject=medical_genetics" : {status: "READY"}
"mmlu:subject=professional_medicine" : {status: "WIP"}  # It will take about ~335,221 tokens to evaluate.
"mmlu:subject=philosophy" : {status: "READY"}
"mmlu:subject=us_foreign_policy" : {status: "READY"}

"real_toxicity_prompts": {status: "READY"}
"twitter_aae:demographic=aa" : {status: "WIP"}

