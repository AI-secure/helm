# Main `RunSpec`s for the benchmarking.

entries: [
  ##### DecodingTrust Trustworthiness Perspectives #####

  ## Toxicity  #####
  # subject: toxic, non-toxic, gpt-3.5, gpt-4

  {description: "decodingtrust_toxicity_prompts:subject=toxic,model=text", priority: 1}
  {description: "decodingtrust_toxicity_prompts:subject=non-toxic,model=text", priority: 1}
  {description: "decodingtrust_toxicity_prompts:subject=gpt-3.5,model=text", priority: 1}
  {description: "decodingtrust_toxicity_prompts:subject=gpt-4,model=text", priority: 1}

  ## Robustness to Adversarial Text Input #####
  # Tasks: SST-2, MNLI, MNLI(-mm), QQP, QNLI, RTE

  {description: "adv_robustness:task=sst2,model=text", priority: 1}
  {description: "adv_robustness:task=qqp,model=text", priority: 1}
  {description: "adv_robustness:task=mnli,model=text", priority: 1}
  {description: "adv_robustness:task=mnli-mm,model=text", priority: 1}
  {description: "adv_robustness:task=rte,model=text", priority: 1}
  {description: "adv_robustness:task=qnli,model=text", priority: 1}

  ## OOD robustness ##
  # Tasks: OOD styles (SST-2)
  {description: "ood_robustness:ood_type=style,task=shake_w,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=augment,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=shake_p0,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=-1,idk=0"}

  #Task: OOD in-context demonstrations (style)
  {description: "ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=2,idk=0"}

  #Task: OOD knowledge
  {description: "ood_robustness:ood_type=knowledge,task=qa_2023,demo_name=2021_qa,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2023,demo_name=2021_qa,run_id=-1,idk=1"}

  #Task: OOD in-context demonstrations (domain)
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=global_facts,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=global_facts,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=global_facts,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=machine_learning,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=machine_learning,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=machine_learning,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=moral_scenarios,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=moral_scenarios,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=moral_scenarios,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=us_foreign_policy,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=us_foreign_policy,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=us_foreign_policy,run_id=2,idk=0"}


  ### Machine Ethics ###
  # Machine Ethics: evaluation on standard benchmarks
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=0,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on short commonsense morality subset of ETHICS dataset under zero-shot setting
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=0,few_shot_num=32,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on short commonsense morality subset of ETHICS dataset under few-shot setting
  {description: "machine_ethics:data_name="ethics_commonsense_long”,test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=0,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on long commonsense morality subset of ETHICS dataset under zero-shot setting
  {description: "machine_ethics:data_name="ethics_commonsense_long”,test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=0,few_shot_num=8,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on long commonsense morality subset of ETHICS dataset under few-shot setting
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=0,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on Jiminy Cricket dataset under zero-shot setting
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=0,few_shot_num=3,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on Jiminy Cricket dataset under few-shot setting
  
  # Machine Ethics: evaluation on jailbreaking prompts
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=1,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=2,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=3,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset 
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=4,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=5,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset
  
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=1,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=2,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=3,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=4,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=5,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  
  # Machine Ethics: evaluation on evasive sentences
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=1”} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=2”} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=3”} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=4”} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=5”} # Evaluation on jailbreaking prompts on ETHICS dataset
  
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=1”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=2”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=3”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=4”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=5”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset


]
