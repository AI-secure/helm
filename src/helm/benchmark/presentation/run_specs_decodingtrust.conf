# Main `RunSpec`s for the benchmarking.

entries: [
  ##### DecodingTrust Trustworthiness Perspectives #####

  ## Toxicity  #####
  # subject: toxic, non-toxic, gpt-3.5, gpt-4

  {description: "decodingtrust_toxicity_prompts:subject=toxic,model=text", priority: 1}
  {description: "decodingtrust_toxicity_prompts:subject=non-toxic,model=text", priority: 1}
  {description: "decodingtrust_toxicity_prompts:subject=gpt-3.5,model=text", priority: 1}
  {description: "decodingtrust_toxicity_prompts:subject=gpt-4,model=text", priority: 1}

  ## Stereotype bias  #####
  # Tasks: all

  {description: "stereotype_bias:task=all,model=text", priority: 1}

  ## Robustness to Adversarial Text Input #####
  # Tasks: SST-2, MNLI, MNLI(-mm), QQP, QNLI, RTE

  {description: "adv_robustness:task=sst2,model=text", priority: 1}
  {description: "adv_robustness:task=qqp,model=text", priority: 1}
  {description: "adv_robustness:task=mnli,model=text", priority: 1}
  {description: "adv_robustness:task=mnli-mm,model=text", priority: 1}
  {description: "adv_robustness:task=rte,model=text", priority: 1}
  {description: "adv_robustness:task=qnli,model=text", priority: 1}

  ## OOD robustness ##
  # Tasks: OOD styles (SST-2)
  {description: "ood_robustness:ood_type=style,task=shake_w,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=augment,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=shake_p0,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0,demo_name=base,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=-1,idk=0"}

  #Task: OOD in-context demonstrations (style)
  {description: "ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=2,idk=0"}

  #Task: OOD knowledge
  {description: "ood_robustness:ood_type=knowledge,task=qa_2023,demo_name=2021_qa,run_id=-1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2023,demo_name=2021_qa,run_id=-1,idk=1"}

  #Task: OOD in-context demonstrations (domain)
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=global_facts,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=global_facts,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=global_facts,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=machine_learning,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=machine_learning,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=machine_learning,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=moral_scenarios,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=moral_scenarios,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=moral_scenarios,run_id=2,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=us_foreign_policy,run_id=0,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=us_foreign_policy,run_id=1,idk=0"}
  {description: "ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=us_foreign_policy,run_id=2,idk=0"}

  ### Adv_demonstration ###
  # for counterfactual 
  {description: "adv_demonstration:perspective=counterfactual,data=snli_premise,demo_name=demo+cf,description=nli3"}
  {description: "adv_demonstration:perspective=counterfactual,data=snli_hypothesis,demo_name=demo+cf,description=nli3"}
  {description: "adv_demonstration:perspective=counterfactual,data=control_raising,demo_name=demo+cf,description=control_raising"}
  {description: "adv_demonstration:perspective=counterfactual,data=irregular_form,demo_name=demo+cf,description=irregular_form"}
  {description: "adv_demonstration:perspective=counterfactual,data=main_verb,demo_name=demo+cf,description=main_verb"}
  {description: "adv_demonstration:perspective=counterfactual,data=syntactic_category,demo_name=demo+cf,description=syntactic_category"}
  # for spurious
  {description: "adv_demonstration:perspective=spurious,data=PP,demo_name=entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=adverb,demo_name=entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=embedded_under_verb,demo_name=entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=l_relative_clause,demo_name=entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=passive,demo_name=entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=s_relative_clause,demo_name=entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=PP,demo_name=non-entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=adverb,demo_name=non-entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=embedded_under_verb,demo_name=non-entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=l_relative_clause,demo_name=non-entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=passive,demo_name=non-entail-bias,description=nli2"}
  {description: "adv_demonstration:perspective=spurious,data=s_relative_clause,demo_name=non-entail-bias,description=nli2"}
  # for backdoor
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_badword,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_badword,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_badword,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_addsent,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_addsent,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_addsent,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_synbkd,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_synbkd,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_synbkd,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_stylebkd,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_stylebkd,description=sa"}
  {description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_stylebkd,description=sa"}

  #{description: "adv_demonstration:perspective=counterfactual,data=snli_premise,demo_name=demo,description=nli3"}
  #{description: "adv_demonstration:perspective=counterfactual,data=snli_hypothesis,demo_name=demo,description=nli3"}
  #{description: "adv_demonstration:perspective=counterfactual,data=snli_premise,demo_name=cf,description=nli3"}
  #{description: "adv_demonstration:perspective=counterfactual,data=snli_hypothesis,demo_name=cf,description=nli3"}
  #{description: "adv_demonstration:perspective=counterfactual,data=snli_premise,demo_name=zero,description=nli3"}
  #{description: "adv_demonstration:perspective=counterfactual,data=snli_hypothesis,demo_name=zero,description=nli3"}
  #{description: "adv_demonstration:perspective=counterfactual,data=control_raising,demo_name=demo,description=control_raising"}
  #{description: "adv_demonstration:perspective=counterfactual,data=irregular_form,demo_name=demo,description=irregular_form"}
  #{description: "adv_demonstration:perspective=counterfactual,data=main_verb,demo_name=demo,description=main_verb"}
  #{description: "adv_demonstration:perspective=counterfactual,data=syntactic_category,demo_name=demo,description=syntactic_category"}
  #{description: "adv_demonstration:perspective=counterfactual,data=control_raising,demo_name=cf,description=control_raising"}
  #{description: "adv_demonstration:perspective=counterfactual,data=irregular_form,demo_name=cf,description=irregular_form"}
  #{description: "adv_demonstration:perspective=counterfactual,data=main_verb,demo_name=cf,description=main_verb"}
  #{description: "adv_demonstration:perspective=counterfactual,data=syntactic_category,demo_name=cf,description=syntactic_category"}
  #{description: "adv_demonstration:perspective=counterfactual,data=control_raising,demo_name=zero,description=control_raising"}
  #{description: "adv_demonstration:perspective=counterfactual,data=irregular_form,demo_name=zero,description=irregular_form"}
  #{description: "adv_demonstration:perspective=counterfactual,data=main_verb,demo_name=zero,description=main_verb"}
  #{description: "adv_demonstration:perspective=counterfactual,data=syntactic_category,demo_name=zero,description=syntactic_category"}

  #{description: "adv_demonstration:perspective=spurious,data=PP,demo_name=zero,description=nli2"}
  #{description: "adv_demonstration:perspective=spurious,data=adverb,demo_name=zero,description=nli2"}
  #{description: "adv_demonstration:perspective=spurious,data=embedded_under_verb,demo_name=zero,description=nli2"}
  #{description: "adv_demonstration:perspective=spurious,data=l_relative_clause,demo_name=zero,description=nli2"}
  #{description: "adv_demonstration:perspective=spurious,data=passive,demo_name=zero,description=nli2"}
  #{description: "adv_demonstration:perspective=spurious,data=s_relative_clause,demo_name=zero,description=nli2"}#

  #{description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_cf_first,description=sa"}
  #{description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_cf_first,description=sa"}
  #{description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_cf_middle,description=sa"}
  #{description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_cf_middle,description=sa"}
  #{description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_cf_end,description=sa"}
  #{description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_cf_end,description=sa"}
  #{description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_badword_0,description=sa"}
  #{description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_badword_1,description=sa"}
  #{description: "adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_badword,description=badword"}
  ###

  ### Privacy ###
  # Task: privacy understanding 
  
  {description: "privacy:scenario_name=privacy_understanding,data_file='',template=0,few_shot_num=0,dataset_size=100,prompt_type=1"}
  {description: "privacy:scenario_name=privacy_understanding,data_file='',template=0,few_shot_num=0,dataset_size=100,prompt_type=2"}
  {description: "privacy:scenario_name=privacy_understanding,data_file='',template=0,few_shot_num=0,dataset_size=100,prompt_type=3"}
  
  # Task: privacy pii
  {description: "privacy:scenario_name=pii,data_file=enron_data/five_shot.pkl,template=1,few_shot_num=0,dataset_size=100,prompt_type=attack"}
  {description: "privacy:scenario_name=pii,data_file=enron_data/five_shot.pkl,template=3,few_shot_num=0,dataset_size=100,prompt_type=attack"}
  {description: "privacy:scenario_name=pii,data_file=enron_data/five_shot.pkl,template=3,few_shot_num=0,dataset_size=100,prompt_type=protect"}

  # task: train data extraction on enron email
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=context-50"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=context-100"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=context-200"}

  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=5,dataset_size=0,prompt_type=five-shot-a"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=5,dataset_size=0,prompt_type=five-shot-b"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=5,dataset_size=0,prompt_type=five-shot-c"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=5,dataset_size=0,prompt_type=five-shot-d"}

  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=1,dataset_size=0,prompt_type=one-shot-a"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=1,dataset_size=0,prompt_type=one-shot-b"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=1,dataset_size=0,prompt_type=one-shot-c"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=1,dataset_size=0,prompt_type=one-shot-d"}

  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=knownzero-shot-a"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=knownzero-shot-b"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=knownzero-shot-c"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=knownzero-shot-d"}

  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=5,dataset_size=0,prompt_type=five-shot-non-domain-a"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=5,dataset_size=0,prompt_type=five-shot-non-domain-b"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=5,dataset_size=0,prompt_type=five-shot-non-domain-c"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=5,dataset_size=0,prompt_type=five-shot-non-domain-d"}

  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=1,dataset_size=0,prompt_type=one-shot-non-domain-a"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=1,dataset_size=0,prompt_type=one-shot-non-domain-b"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=1,dataset_size=0,prompt_type=one-shot-non-domain-c"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=1,dataset_size=0,prompt_type=one-shot-non-domain-d"}

  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=zero-shot-a"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=zero-shot-b"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=zero-shot-c"}
  {description: "privacy:scenario_name=enron_email_extraction,data_file=enron_data,template=0,few_shot_num=0,dataset_size=0,prompt_type=zero-shot-d"}


  ### Machine Ethics ###
  # Machine Ethics: evaluation on standard benchmarks
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=0,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on short commonsense morality subset of ETHICS dataset under zero-shot setting
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=0,few_shot_num=32,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on short commonsense morality subset of ETHICS dataset under few-shot setting
  {description: "machine_ethics:data_name="ethics_commonsense_long”,test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=0,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on long commonsense morality subset of ETHICS dataset under zero-shot setting
  {description: "machine_ethics:data_name="ethics_commonsense_long”,test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=0,few_shot_num=8,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on long commonsense morality subset of ETHICS dataset under few-shot setting
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=0,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on Jiminy Cricket dataset under zero-shot setting
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=0,few_shot_num=3,jailbreak_prompt=0,evasive_sentence=0"} # Evaluation on Jiminy Cricket dataset under few-shot setting
  
  # Machine Ethics: evaluation on jailbreaking prompts
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=1,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=2,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=3,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset 
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=4,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=5,evasive_sentence=0"} # Evaluation on jailbreaking prompts on ETHICS dataset
  
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=1,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=2,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=3,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=4,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=5,evasive_sentence=0"} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  
  # Machine Ethics: evaluation on evasive sentences
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=1”} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=2”} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=3”} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=4”} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "machine_ethics:data_name="ethics_commonsense_short",test_data_file="ethics/commonsense/cm_test.csv",train_data_file="ethics/commonsense/cm_train.csv",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=5”} # Evaluation on jailbreaking prompts on ETHICS dataset
  
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=1”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=2”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=3”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=4”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "machine_ethics:data_name=“jiminy”,test_data_file="jiminy_test.json",train_data_file="jiminy_train.json",test_num=200,few_shot_num=0,jailbreak_prompt=0,evasive_sentence=5”} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset


]
