import json
import os
from typing import List, Dict

from common.general import ensure_file_downloaded, ensure_directory_exists
from .scenario import Scenario, Instance, Reference, TRAIN_TAG, VALID_TAG, CORRECT_TAG


class BoolQScenario(Scenario):
    """
    The BoolQ dataset is from the paper:
        https://arxiv.org/abs/1905.10044

    Original repository can be found at:
        https://github.com/google-research-datasets/boolean-questions

    BoolQ is a QA dataset containing 15942 (9427 training, 3270 dev, 3245 test) boolean (yes/no) questions.
    Each sample contains a passage, a question and an answer that are generated in an unconstrained/unprompted setting.

    We prompt models using the following format:
        <passage>
        question: <question>
        answer:

        Target completion:
            <answer>

    Using an example from the training dataset, we have
        Epsom railway station serves the town of Epsom in Surrey. It is located off Waterloo Road and is
        less than two minutes' walk from the High Street.
        It is not in the London Oyster card zone unlike Epsom Downs or Tattenham Corner stations.
        The station building was replaced in 2012/2013 with a new building with apartments above the station.
        question: can you use oyster card at epsom station
        answer:

        Target completion:
            yes
    """

    name = "boolq"
    description = "Question answering dataset with naturally occuring yes/no questions."
    tags = ["question_answering"]

    def __init__(self):
        pass

    def get_context(self, passage: str, question: str):
        return f"{passage}\nquestion:{question}"

    def get_split_instances(self, split_path: str, tags: List[str]) -> List[Instance]:
        split_instances: List[Instance] = []
        with open(split_path, "r") as f:
            all_triplets = list(f)
            for item in all_triplets:
                triplet: Dict = json.loads(item)
                passage: str = triplet["passage"]
                question: str = triplet["question"]
                answer: bool = triplet["answer"]

                correct_answer = "yes" if answer else "no"
                context = self.get_context(passage, question)
                instance: Instance = Instance(
                    input=context, references=[Reference(output=correct_answer, tags=[CORRECT_TAG])], tags=tags
                )
                split_instances.append(instance)
        return split_instances

    def get_instances(self) -> List[Instance]:
        data_path = os.path.join(self.output_path, "data")
        ensure_directory_exists(data_path)

        instances: List[Instance] = []
        splits = {"train": TRAIN_TAG, "dev": VALID_TAG}

        # First, ensure all splits are downloaded
        for split in splits:
            url = f"https://storage.googleapis.com/boolq/{split}.jsonl"
            target_path: str = os.path.join(data_path, f"{split}.jsonl")
            ensure_file_downloaded(source_url=url, target_path=target_path, unpack=False)

        for split in splits:
            split_path: str = os.path.join(data_path, f"{split}.jsonl")
            tags: List[str] = [splits[split]]
            instances.extend(self.get_split_instances(split_path, tags))
        return instances


class BoolQContrastSetScenario(BoolQScenario):
    """
    Contrast Sets for The BoolQ dataset is from the paper:
        https://arxiv.org/abs/2004.02709

    Original repository can be found at:
        https://github.com/allenai/contrast-sets

    Each sample contains the original <passage, question, answer> triplet, and the human-perturbed version
    i.e. <passage, perturbed question, perturbed answer>.

    Contrast Sets for BoolQ contains 339 perturbed questions, forming 70 contrast sets in total.
    Perturbations to the original questions are generated by humans, with the intention of flipping the gold label.
    For more details, see the original paper, Appendix B.9.

    We prompt models using the same format as BoolQ:
        <passage>
        question: <question>
        answer:

        Target completion:
            <answer>

    An example instance of a perturbation (from the original paper):
    The Fate of the Furious premiered in Berlin on April 4, 2017, and was theatrically released in the
    United States on April 14, 2017, playing in 3D, IMAX 3D and 4DX internationally. . . A spinoff film starring
    Johnson and Statham’s characters is scheduled for release in August 2019, while the ninth and tenth films are
    scheduled for releases on the years 2020 and 2021.
    question: is “Fate and the Furious” the last movie?
    answer: no

    perturbed question: is “Fate and the Furious” the first of multiple movies?
    perturbed answer: yes
    perturbation strategy: adjective change.
    """

    name = "boolq-contrast-sets"
    description = "Contrast Sets for BoolQ question answering dataset with naturally occuring yes/no questions."
    tags = ["question_answering", "robustness"]

    def __init__(self):
        pass

    def get_instances(self) -> List[Instance]:
        data_path = os.path.join(self.output_path, "data")
        ensure_directory_exists(data_path)

        # Ensure the training instances for BoolQ are downloaded
        # Note: Contrast Sets are constructed using the dev set of the original BoolQ dataset.
        # Hence, it is safe to use training examples as the in-context examples.

        url = "https://storage.googleapis.com/boolq/train.jsonl"
        split_path: str = os.path.join(data_path, "train.jsonl")
        ensure_file_downloaded(source_url=url, target_path=split_path, unpack=False)

        training_tags: List[str] = [TRAIN_TAG]
        training_instances: List[Instance] = self.get_split_instances(split_path, training_tags)

        # Ensure contrast sets are downloaded
        url = "https://raw.githubusercontent.com/allenai/contrast-sets/main/BoolQ/boolq_perturbed.json"
        target_path: str = os.path.join(data_path, "boolq_perturbed.jsonl")
        ensure_file_downloaded(source_url=url, target_path=target_path, unpack=False)

        contrast_instances: List[Instance] = []

        with open(target_path, encoding="utf-8") as f:
            all_questions = json.load(f)

            for items in all_questions["data"][1:]:
                passage: str = items["paragraph"]

                tags: List[str] = [VALID_TAG]
                for perturbed_item in items["perturbed_questions"]:
                    perturbed_question: str = perturbed_item["perturbed_q"]
                    perturbed_answer: str = "yes" if perturbed_item["answer"] == "TRUE" else "no"
                    perturbed_context: str = self.get_context(passage, perturbed_question)
                    instance: Instance = Instance(
                        input=perturbed_context,
                        references=[Reference(output=perturbed_answer, tags=[CORRECT_TAG])],
                        tags=tags,
                    )
                    contrast_instances.append(instance)

        instances: List[Instance] = training_instances + contrast_instances
        return instances
