# List the RunSpecs that we want to display on the website in this file.
# A RunSpec specifies how to do a single run, which gets a scenario, adapts it, and computes a list of metrics.
#
# RunSpecs are unique. Mark the RunSpec with either READY or WIP (work in progress):
#    For READY RunSpecs, we evaluate and generate metrics.
#    For WIP RunSpecs, we just estimate token usage.
#
# and assign them a priority where a RunSpec with a lower priority value gets run
# before a one with a higher priority value.
#
# Place your new RunSpec description under the appropriate section.

# TODO: Set num_train_trials=3 as the default


##### Generic #####

##### Question Answering #####

# Reading comprehension
"narrative_qa:model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["NarrativeQA"]}
"news_qa:model=text,data_augmentation=canonical": {status: "READY", priority: 3, groups: ["NewsQA"]}
"boolq:model=text,data_augmentation=canonical": {status: "READY", priority: 1, groups: ["BoolQ"]}  
"quac:model=text,data_augmentation=canonical": {status: "READY", priority: 1, groups: ["QuAC"]}  

# Reading comprehension and closedbook QA variants
"natural_qa:model=text,mode=openbook-longans,data_augmentation=canonical": {status: "READY", priority: 1, groups: ["NaturalQuestions (open-book)"]}
"natural_qa:model=text,mode=closedbook,data_augmentation=canonical": {status: "READY", priority: 1, groups: ["NaturalQuestions (closed-book)"]}

# Closed-book QA with multiple choice
"commonsense:model=text,dataset=hellaswag,method=mcqa": {status: "READY", priority: 1, groups: ["HellaSwag"]}
"commonsense:model=text,dataset=openbookqa,method=mcqa": {status: "READY", priority: 2, groups: ["OpenbookQA"]}
"commonsense:model=text,dataset=commonsenseqa,method=mcqa": {status: "READY", priority: 2, groups: ["CommonsenseQA"]}
"truthful_qa:model=text,task=mc_single": {status: "READY", priority: 2, groups: ["TruthfulQA"]}

# For MMLU, we sampled the following 10 subjects, which cover diverse topics across humanities, social sciences and STEM.
"mmlu:model=text,subject=abstract_algebra,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["MMLU"]}
"mmlu:model=text,subject=anatomy,data_augmentation=canonical": {status: "READY", priority: 3, groups: ["MMLU"]}
"mmlu:model=text,subject=college_chemistry,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["MMLU"]}
"mmlu:model=text,subject=computer_security,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["MMLU"]}
"mmlu:model=text,subject=econometrics,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["MMLU"]}
"mmlu:model=text,subject=global_facts,data_augmentation=canonical": {status: "READY", priority: 3, groups: ["MMLU"]}
"mmlu:model=text,subject=jurisprudence,data_augmentation=canonical": {status: "READY", priority: 3, groups: ["MMLU"]}
"mmlu:model=text,subject=philosophy,data_augmentation=canonical": {status: "READY", priority: 3, groups: ["MMLU"]}
"mmlu:model=text,subject=professional_medicine,data_augmentation=canonical": {status: "READY", priority: 3, groups: ["MMLU"]}  
"mmlu:model=text,subject=us_foreign_policy,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["MMLU"]}
"mmlu:model=text,subject=astronomy,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=business_ethics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=clinical_knowledge,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=college_biology,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=college_computer_science,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=college_mathematics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=college_medicine,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=college_physics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=conceptual_physics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=electrical_engineering,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=elementary_mathematics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=formal_logic,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_biology,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_chemistry,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_computer_science,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_european_history,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_geography,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_government_and_politics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_macroeconomics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_mathematics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_microeconomics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_physics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_psychology,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_statistics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_us_history,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=high_school_world_history,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=human_aging,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=human_sexuality,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=international_law,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=logical_fallacies,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=machine_learning,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=management,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=marketing,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=medical_genetics,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=miscellaneous,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=moral_disputes,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=moral_scenarios,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=nutrition,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=prehistory,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=professional_accounting,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=professional_law,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=professional_psychology,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=public_relations,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=security_studies,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=sociology,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=virology,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}
"mmlu:model=text,subject=world_religions,data_augmentation=canonical": {status: "READY", priority: 4, groups: ["MMLU"]}


##### Information Retrieval #####
# Scenarios: MS Marco, TREC

# TODO: rename scenario to msmarco, track to msmarco - Issue 527
# TODO: Update valid_topk=30 based on AI21 results
"msmarco:task=passage,model=full_functionality_text,track=regular,use_qrels_passages=True,use_topk_passages=True,valid_topk=30,num_valid_queries=200": {status: "READY", priority: 2, groups: ["MS MARCO (regular)"]}
"msmarco:task=passage,model=full_functionality_text,track=trec,use_qrels_passages=True,use_topk_passages=True,valid_topk=30": {status: "READY", priority: 1, groups: ["MS MARCO (TREC)"]}
"msmarco:task=passage,model=full_functionality_text,track=regular,use_qrels_passages=False,use_topk_passages=True,valid_topk=30,num_valid_queries=200": {status: "READY", priority: 2, groups: ["MS MARCO (regular)"]}
"msmarco:task=passage,model=full_functionality_text,track=trec,use_qrels_passages=False,use_topk_passages=True,valid_topk=30": {status: "READY", priority: 1, groups: ["MS MARCO (TREC)"]}


##### Summarization #####
# Scenarios: XSUM, CNN/DM

"summarization_cnndm:model=text,temperature=0.3": {status: "READY", priority: 1, groups: ["CNN/DailyMail"]}
"summarization_xsum_sampled:model=text,temperature=0.3": {status: "READY", priority: 1, groups: ["XSUM"]}


##### Text Classification #####
# Scenarios: IMDB, RAFT, CivilComments

"imdb:model=text,data_augmentation=canonical": {status: "READY", priority: 1, groups: ["IMDB"]}

"raft:subset=ade_corpus_v2,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=banking_77,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=neurips_impact_statement_risks,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=one_stop_english,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=overruling,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=semiconductor_org_types,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=tweet_eval_hate,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=twitter_complaints,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=systematic_review_inclusion,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=tai_safety_research,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}
"raft:subset=terms_of_service,model=text,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["RAFT"]}

"entity_matching:model=text,dataset=Beer,data_augmentation=canonical": {status: "READY", priority: 1, groups: ["Entity matching"]}
"entity_matching:model=text,dataset=Abt_Buy,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["Entity matching"]}
"entity_matching:model=text,dataset=Dirty_iTunes_Amazon,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["Entity matching"]}

"entity_data_imputation:model=text,dataset=Buy,data_augmentation=canonical": {status: "READY", priority: 1, groups: ["Data imputation"]}
"entity_data_imputation:model=text,dataset=Restaurant,data_augmentation=canonical": {status: "READY", priority: 2, groups: ["Data imputation"]}

# TODO: remove data path - Issue 528
# Performance disparities
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=all": {status: "READY", priority: 1, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=asian": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=atheist": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=bisexual": {status: "READY", priority: 2, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=black": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=buddhist": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=christian": {status: "READY", priority: 2, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=female": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=heterosexual": {status: "READY", priority: 2, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=hindu": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=homosexual_gay_or_lesbian": {status: "READY", priority: 2, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=intellectual_or_learning_disability": {status: "READY", priority: 2, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=jewish": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=latino": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=male": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=muslim": {status: "READY", priority: 2, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=other_disability": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=other_gender": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=other_race_or_ethnicity": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=other_religion": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=other_sexual_orientation": {status: "READY", priority: 3, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=physical_disability": {status: "READY", priority: 2, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=psychiatric_or_mental_illness": {status: "READY", priority: 2, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=transgender": {status: "READY", priority: 2, groups: ["CivilComments"]}
"civil_comments:model=text,data_augmentation=canonical,data_path=/u/scr/nlp/crfm/benchmarking/civil_comments/,subject=white": {status: "READY", priority: 3, groups: ["CivilComments"]}


##### Component Skills and Risks #####

##### Language #####
# Scenarios: BLiMP, The Pile, ICE, WikiText-103, TwitterAAE

# TODO: convert this into multiple choice, and let adaptation handle it (input empty, references are the two sentences)
"blimp:model=full_functionality_text,phenomenon=island_effects": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=anaphor_agreement": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=argument_structure": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=determiner_noun_agreement": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=subject_verb_agreement": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=ellipsis": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=control_raising": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=quantifiers": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=irregular_forms": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=npi_licensing": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=binding": {status: "READY", priority: 3, groups: ["BLiMP"]}
"blimp:model=full_functionality_text,phenomenon=filler_gap_dependency": {status: "READY", priority: 3, groups: ["BLiMP"]}

## Language modeling

"wikitext_103:model=full_functionality_text": {status: "READY", priority: 3, groups: ["WikiText-103"]}

"the_pile:model=full_functionality_text,subset=ArXiv": {status: "READY", priority: 2, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=BookCorpus2": {status: "READY", priority: 2, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=Books3": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=DM Mathematics": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=Enron Emails": {status: "READY", priority: 2, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=EuroParl": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=FreeLaw": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=Github": {status: "READY", priority: 2, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=Gutenberg (PG-19)": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=HackerNews": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=NIH ExPorter": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=OpenSubtitles": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=OpenWebText2": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=PhilPapers": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=Pile-CC": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=PubMed Abstracts": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=PubMed Central": {status: "READY", priority: 2, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=StackExchange": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=USPTO Backgrounds": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=Ubuntu IRC": {status: "READY", priority: 3, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=Wikipedia (en)": {status: "READY", priority: 2, groups: ["The Pile"]}
"the_pile:model=full_functionality_text,subset=YoutubeSubtitles": {status: "READY", priority: 3, groups: ["The Pile"]}

"twitter_aae:model=full_functionality_text,demographic=aa": {status: "READY", priority: 1, groups: ["TwitterAAE (AAE)", "TwitterAAE"]}
"twitter_aae:model=full_functionality_text,demographic=white": {status: "READY", priority: 1, groups: ["TwitterAAE (White)", "TwitterAAE"]}

"ice:model=full_functionality_text,subset=CAN": {status: "READY", priority: 3, groups: ["ICE (Canada)", "ICE"]}
# TODO: @Nathan - Add East Africa.
"ice:model=full_functionality_text,subset=HK": {status: "READY", priority: 2, groups: ["ICE (Hong Kong)", "ICE"]}
"ice:model=full_functionality_text,subset=IND": {status: "READY", priority: 2, groups: ["ICE (India)", "ICE"]}
"ice:model=full_functionality_text,subset=JA": {status: "READY", priority: 3, groups: ["ICE (Japan)", "ICE"]}
"ice:model=full_functionality_text,subset=PHI": {status: "READY", priority: 3, groups: ["ICE (Phillipines)", "ICE"]}
"ice:model=full_functionality_text,subset=SIN": {status: "READY", priority: 3, groups: ["ICE (Singapore)", "ICE"]}
"ice:model=full_functionality_text,subset=USA": {status: "READY", priority: 2, groups: ["ICE (USA)", "ICE"]}

# TODO: not reproducible: https://github.com/stanford-crfm/benchmarking/issues/467
# "ice:model=full_functionality_text,split=spoken": {status: "READY", priority: 3, groups: ["ICE (spoken)", "ICE"]}
# "ice:model=full_functionality_text,split=written": {status: "READY", priority: 3, groups: ["ICE (written)", "ICE"]}
# "ice:model=full_functionality_text,gender=F": {status: "READY", priority: 2, groups: ["ICE (female)", "ICE"]}
# "ice:model=full_functionality_text,gender=M": {status: "READY", priority: 2, groups: ["ICE (male)", "ICE"]}


##### Knowledge #####

# For WikiFact, we sampled the following 10 relation types, which cover diverse topics
# across general facts, humanities, social sciences and STEM.
"wikifact:model=text,k=5,subject=P1620": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P19": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P2175": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P31": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P36": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P38": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P39": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P50": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P61": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P780": {status: "READY", priority: 2, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1001": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P101": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P102": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P103": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P106": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P108": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P111": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1136": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P122": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P127": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1303": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1304": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P131": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1313": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P135": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P136": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1376": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P138": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P140": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1412": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P159": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1591": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P166": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P17": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P170": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P176": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P178": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P189": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P190": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1906": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P1923": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P20": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P2176": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P2293": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P2384": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P2568": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P264": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P27": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P276": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P277": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P279": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P30": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P3014": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P306": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P35": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P355": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P361": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P364": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P37": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P4006": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P4044": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P407": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P413": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P414": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P449": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P449": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P449": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P452": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P463": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P47": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P495": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P527": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P530": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P54": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P57": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P5826": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P6": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P69": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P737": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P740": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P8111": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P86": {status: "READY", priority: 4, groups: ["WikiFact"]}
"wikifact:model=text,k=5,subject=P937": {status: "READY", priority: 4, groups: ["WikiFact"]}

##### Reasoning #####

# Evaluate all text and Codex models for all reasoning tasks

## Synthetic
"numeracy:model=all,run_solver=True,relation_type=linear,mode=function": {status: "READY", priority: 2, groups: ["Numeracy"]}
"numeracy:model=all,run_solver=True,relation_type=plane,mode=function": {status: "READY", priority: 3, groups: ["Numeracy"]}

# The DistanceMetric is slow to compute for relation_type 'parabola' and 'paraboloid', so set run_solver=False
"numeracy:model=all,run_solver=False,relation_type=parabola,mode=function": {status: "READY", priority: 4, groups: ["Numeracy"]}
"numeracy:model=all,run_solver=False,relation_type=paraboloid,mode=function": {status: "READY", priority: 4, groups: ["Numeracy"]}

"synthetic_reasoning:model=all,mode=pattern_match": {status: "READY", priority: 2, groups: ["Synthetic reasoning (abstract symbols)"]}
"synthetic_reasoning:model=all,mode=variable_substitution": {status: "READY", priority: 2, groups: ["Synthetic reasoning (abstract symbols)"]}
"synthetic_reasoning:model=all,mode=induction": {status: "READY", priority: 2, groups: ["Synthetic reasoning (abstract symbols)"]}

"synthetic_reasoning_natural:model=all,difficulty=easy": {status: "READY", priority: 2, groups: ["Synthetic reasoning (natural language)"]}
"synthetic_reasoning_natural:model=all,difficulty=hard": {status: "READY", priority: 2, groups: ["Synthetic reasoning (natural language)"]}

"babi_qa:model=all,task=1": {status: "READY", priority: 3, groups: ["bAbI"]}
"babi_qa:model=all,task=2": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=3": {status: "READY", priority: 2, groups: ["bAbI"]}
"babi_qa:model=all,task=4": {status: "READY", priority: 3, groups: ["bAbI"]}
"babi_qa:model=all,task=5": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=6": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=7": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=8": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=9": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=10": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=11": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=12": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=13": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=14": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=15": {status: "READY", priority: 2, groups: ["bAbI"]}
"babi_qa:model=all,task=16": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=17": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=18": {status: "READY", priority: 4, groups: ["bAbI"]}
"babi_qa:model=all,task=19": {status: "READY", priority: 2, groups: ["bAbI"]}
"babi_qa:model=all,task=20": {status: "READY", priority: 4, groups: ["bAbI"]}

"dyck_language:model=all,num_parenthesis_pairs=2": {status: "READY", priority: 4, groups: ["Dyck"]}
"dyck_language:model=all,num_parenthesis_pairs=3": {status: "READY", , priority: 2, groups: ["Dyck"]}
"dyck_language:model=all,num_parenthesis_pairs=4": {status: "READY", priority: 4, groups: ["Dyck"]}

## Real

# Roughly reproduce MATH settings:
"math:model=all,subject=number_theory,level=1,use_official_examples=True": {status: "READY", priority: 2, groups: ["MATH"]}
"math:model=all,subject=intermediate_algebra,level=1,use_official_examples=True": {status: "READY", priority: 2, groups: ["MATH"]}
"math:model=all,subject=algebra,level=1,use_official_examples=True": {status: "READY", priority: 2, groups: ["MATH"]}
"math:model=all,subject=prealgebra,level=1,use_official_examples=True": {status: "READY", priority: 2, groups: ["MATH"]}
"math:model=all,subject=geometry,level=1,use_official_examples=True": {status: "READY", priority: 2, groups: ["MATH"]}
"math:model=all,subject=counting_and_probability,level=1,use_official_examples=True": {status: "READY", priority: 2, groups: ["MATH"]}
"math:model=all,subject=precalculus,level=1,use_official_examples=True": {status: "READY", priority: 2, groups: ["MATH"]}

"math:model=all,subject=number_theory,level=2,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=intermediate_algebra,level=2,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=algebra,level=2,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=prealgebra,level=2,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=geometry,level=2,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=counting_and_probability,level=2,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=precalculus,level=2,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}

"math:model=all,subject=number_theory,level=3,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=intermediate_algebra,level=3,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=algebra,level=3,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=prealgebra,level=3,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=geometry,level=3,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=counting_and_probability,level=3,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=precalculus,level=3,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}

"math:model=all,subject=number_theory,level=4,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=intermediate_algebra,level=4,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=algebra,level=4,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=prealgebra,level=4,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=geometry,level=4,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=counting_and_probability,level=4,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}
"math:model=all,subject=precalculus,level=4,use_official_examples=True": {status: "READY", priority: 4, groups: ["MATH"]}

"math:model=all,subject=number_theory,level=5,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=intermediate_algebra,level=5,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=algebra,level=5,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=prealgebra,level=5,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=geometry,level=5,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=counting_and_probability,level=5,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}
"math:model=all,subject=precalculus,level=5,use_official_examples=True": {status: "READY", priority: 3, groups: ["MATH"]}

# With chain-of-thought prompting:
"math:model=all,subject=number_theory,level=1,use_chain_of_thought=True": {status: "READY", priority: 2, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=intermediate_algebra,level=1,use_chain_of_thought=True": {status: "READY", priority: 2, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=algebra,level=1,use_chain_of_thought=True": {status: "READY", priority: 2, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=prealgebra,level=1,use_chain_of_thought=True": {status: "READY", priority: 2, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=geometry,level=1,use_chain_of_thought=True": {status: "READY", priority: 2, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=counting_and_probability,level=1,use_chain_of_thought=True": {status: "READY", priority: 2, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=precalculus,level=1,use_chain_of_thought=True": {status: "READY", priority: 2, groups: ["MATH (chain-of-thoughts)"]}

"math:model=all,subject=number_theory,level=2,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=intermediate_algebra,level=2,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=algebra,level=2,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=prealgebra,level=2,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=geometry,level=2,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=counting_and_probability,level=2,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=precalculus,level=2,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}

"math:model=all,subject=number_theory,level=3,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=intermediate_algebra,level=3,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=algebra,level=3,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=prealgebra,level=3,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=geometry,level=3,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=counting_and_probability,level=3,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=precalculus,level=3,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}

"math:model=all,subject=number_theory,level=4,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=intermediate_algebra,level=4,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=algebra,level=4,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=prealgebra,level=4,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=geometry,level=4,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=counting_and_probability,level=4,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=precalculus,level=4,use_chain_of_thought=True": {status: "READY", priority: 4, groups: ["MATH (chain-of-thoughts)"]}

"math:model=all,subject=number_theory,level=5,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=intermediate_algebra,level=5,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=algebra,level=5,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=prealgebra,level=5,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=geometry,level=5,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=counting_and_probability,level=5,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}
"math:model=all,subject=precalculus,level=5,use_chain_of_thought=True": {status: "READY", priority: 3, groups: ["MATH (chain-of-thoughts)"]}

"gsm:model=all": {status: "READY", priority: 2, groups: ["GSM8K"]}

"lsat_qa:model=all,task=all": {status: "READY", priority: 2, groups: ["LSAT"]}
"lsat_qa:model=all,task=grouping": {status: "READY", priority: 3, groups: ["LSAT"]}
"lsat_qa:model=all,task=ordering": {status: "READY", priority: 3, groups: ["LSAT"]}
"lsat_qa:model=all,task=assignment": {status: "READY", priority: 3, groups: ["LSAT"]}
"lsat_qa:model=all,task=miscellaneous": {status: "READY", priority: 3, groups: ["LSAT"]}

# Legal reasoning
"legal_support:model=all": {status: "READY", priority: 2, groups: ["LegalSupport"]}

# Code
"code:model=code,dataset=HumanEval": {status: "READY", priority: 1, groups: ["HumanEval"]}
"code:model=code,dataset=APPS": {status: "READY", priority: 1, groups: ["APPS"]}


##### Harms #####

# Randomly sampled instances from the original BooksCorpus.
# We expect data here to be less repeated in the pretraining corpus. This approximates the average case.
"copyright:model=text,datatag=n_books_1000-extractions_per_book_1-prefix_length_125": {status: "READY", priority: 1, groups: ["Copyright"]}

# We expect data here to be repeated more in the pretraining corpus. This approximates the worst case.
"copyright:model=text,datatag=popular_books-prefix_length_125.json": {status: "READY", priority: 1, groups: ["Copyright"]}

# Large and small codex models.
"copyright:model=code,datatag=prompt_num_line_1-min_lines_20.json": {status: "READY", priority: 2, groups: ["Copyright"]}
"copyright:model=code,datatag=prompt_num_line_5-min_lines_20.json": {status: "READY", priority: 3, groups: ["Copyright"]}
"copyright:model=code,datatag=prompt_num_line_10-min_lines_20.json": {status: "READY", priority: 2, groups: ["Copyright"]}

"disinformation:model=text,capability=reiteration,topic=covid": {status: "READY", priority: 1, groups: ["Disinformation (reiteration)"]}
"disinformation:model=text,capability=reiteration,topic=climate": {status: "READY", priority: 1, groups: ["Disinformation (reiteration)"]}
"disinformation:model=text,capability=wedging": {status: "READY", priority: 1, groups: ["Disinformation (wedging)"]}

# TODO: some are missing instances?
"bbq:model=text,subject=all": {status: "READY", priority: 2, groups: ["BBQ"]}
"bbq:model=text,subject=age": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=disability_status": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=gender_identity": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=nationality": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=physical_appearance": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=race_ethnicity": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=race_x_SES": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=race_x_gender": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=religion": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=SES": {status: "READY", priority: 3, groups: ["BBQ"]}
"bbq:model=text,subject=sexual_orientation": {status: "READY", priority: 3, groups: ["BBQ"]}

### Toxicity
# TODO: consider better prompting (same for RealToxicityPrompts)

# Calculating toxicity metric:
# Empirical probability of generating a span with Toxicity >= 0.5 at least once over k generations
"real_toxicity_prompts:model=text": {status: "READY", priority: 2, groups: ["RealToxicityPrompts"]}

"bold:model=text,subject=all": {status: "READY", priority: 2, groups: ["BOLD"]}
"bold:model=text,subject=gender": {status: "READY", priority: 3, groups: ["BOLD"]}
"bold:model=text,subject=political_ideology": {status: "READY", priority: 3, groups: ["BOLD"]}
"bold:model=text,subject=profession": {status: "READY", priority: 3, groups: ["BOLD"]}
"bold:model=text,subject=race": {status: "READY", priority: 3, groups: ["BOLD"]}
"bold:model=text,subject=religious_ideology": {status: "READY", priority: 3, groups: ["BOLD"]}


##### Efficiency #####

"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1,num_output_tokens=1": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1,num_output_tokens=1": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1,num_output_tokens=2": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1,num_output_tokens=2": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1,num_output_tokens=4": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1,num_output_tokens=4": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1,num_output_tokens=8": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1,num_output_tokens=8": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1,num_output_tokens=16": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1,num_output_tokens=16": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1,num_output_tokens=32": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1,num_output_tokens=32": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1,num_output_tokens=64": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1,num_output_tokens=64": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=512,num_output_tokens=1": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=512,num_output_tokens=1": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=512,num_output_tokens=2": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=512,num_output_tokens=2": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=512,num_output_tokens=4": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=512,num_output_tokens=4": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=512,num_output_tokens=8": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=512,num_output_tokens=8": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=512,num_output_tokens=16": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=512,num_output_tokens=16": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=512,num_output_tokens=32": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=512,num_output_tokens=32": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=512,num_output_tokens=64": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=512,num_output_tokens=64": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1024,num_output_tokens=1": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1024,num_output_tokens=1": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1024,num_output_tokens=2": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1024,num_output_tokens=2": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1024,num_output_tokens=4": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1024,num_output_tokens=4": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1024,num_output_tokens=8": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1024,num_output_tokens=8": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1024,num_output_tokens=16": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1024,num_output_tokens=16": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1024,num_output_tokens=32": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1024,num_output_tokens=32": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1024,num_output_tokens=64": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1024,num_output_tokens=64": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1536,num_output_tokens=1": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1536,num_output_tokens=1": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1536,num_output_tokens=2": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1536,num_output_tokens=2": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1536,num_output_tokens=4": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1536,num_output_tokens=4": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1536,num_output_tokens=8": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1536,num_output_tokens=8": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1536,num_output_tokens=16": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1536,num_output_tokens=16": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1536,num_output_tokens=32": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1536,num_output_tokens=32": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2_tokenizer_fast,num_input_tokens=1536,num_output_tokens=64": {status: "READY", priority: 1, groups: ["Efficiency"]}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21,num_input_tokens=1536,num_output_tokens=64": {status: "READY", priority: 1, groups: ["Efficiency"]}
