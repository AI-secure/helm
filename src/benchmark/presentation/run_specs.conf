# List the RunSpecs that we want to display on the website in this file.
# A RunSpec specifies how to do a single run, which gets a scenario, adapts it, and computes a list of metrics.
#
# RunSpecs are unique. Mark the RunSpec with either READY or WIP (work in progress):
#    For READY RunSpecs, we evaluate and generate metrics.
#    For WIP RunSpecs, we just estimate token usage.
# Place the RunSpecs alphabetically within the sections.

##### Generic #####

"boolq": {status: "WIP"}
"boolq_contrast_sets": {status: "WIP"}


##### Harms #####

"copyright:pilot_study=true": {status: "WIP"}
"copyright:pilot_study=false": {status: "WIP"}
"real_toxicity_prompts": {status: "READY"}


##### Interaction #####


##### Language #####

"twitter_aae:demographic=aa": {status: "WIP"}


##### Knowledge #####

# TODO: should we include all of the 57 subjects available in MMLU?
"mmlu:subject=abstract_algebra": {status: "READY"}
"mmlu:subject=anatomy": {status: "READY"}
"mmlu:subject=college_chemistry": {status: "READY"}
"mmlu:subject=computer_security": {status: "READY"}
"mmlu:subject=econometrics": {status: "READY"}
"mmlu:subject=global_facts": {status: "READY"}
"mmlu:subject=jurisprudence": {status: "READY"}
"mmlu:subject=medical_genetics": {status: "READY"}
"mmlu:subject=professional_medicine": {status: "WIP"}  # It will take about ~335,221 tokens to evaluate.
"mmlu:subject=philosophy": {status: "READY"}
"mmlu:subject=us_foreign_policy": {status: "READY"}


##### Reasoning #####

"lpm:difficulty=easy": {status: "READY"}
"lpm:difficulty=hard": {status: "READY"}
