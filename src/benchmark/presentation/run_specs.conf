# List the RunSpecs that we want to display on the website in this file.
# A RunSpec specifies how to do a single run, which gets a scenario, adapts it, and computes a list of metrics.
#
# RunSpecs are unique. Mark the RunSpec with either READY or WIP (work in progress):
#    For READY RunSpecs, we evaluate and generate metrics.
#    For WIP RunSpecs, we just estimate token usage.
#
# and assign them a priority where a RunSpec with a lower priority value gets run
# before a one with a higher priority value.
#
# Place your new RunSpec description under the appropriate section.

# TODO: Set num_train_trials=3 as the default


##### Generic #####

##### Question Answering #####
# Scenarios: BoolQ, NarrativeQA, NewsQA, QuAC
# Scenarios: NaturalQuestions
# Scenarios: CommonsenseQA, HellaSwag, OpenBookQA, TruthfulQA
# Scenarios: MMLU

## Reading comprehension

"boolq:model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 1}
"narrative_qa:model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"news_qa:model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"quac:model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 1}

## Reading comprehension and closedbook QA variants

"natural_qa:model=text,mode=openbook_longans,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 1}
"natural_qa:model=text,mode=closedbook,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 1}

## Closed-book QA with multiple choice

"commonsense:model=text,dataset=commonsenseqa,method=multiple_choice_separate_calibrated,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
# Adaptation method is set to ADAPT_MULTIPLE_CHOICE_SEPARATE_CALIBRATED and echo=True
"commonsense:model=full_functionality_text,dataset=hellaswag,method=multiple_choice_separate_original,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 1}
"commonsense:model=full_functionality_text,dataset=openbookqa,method=multiple_choice_separate_calibrated,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"truthful_qa:model=text,task=mc_single,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 1}

# For MMLU, we sampled the following 10 subjects, which cover diverse topics across humanities, social sciences and STEM.
"mmlu:model=text,subject=abstract_algebra,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"mmlu:model=text,subject=anatomy,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"mmlu:model=text,subject=college_chemistry,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"mmlu:model=text,subject=computer_security,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"mmlu:model=text,subject=econometrics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"mmlu:model=text,subject=global_facts,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"mmlu:model=text,subject=jurisprudence,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"mmlu:model=text,subject=philosophy,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"mmlu:model=text,subject=professional_medicine,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"mmlu:model=text,subject=us_foreign_policy,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"mmlu:model=text,subject=astronomy,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=business_ethics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=clinical_knowledge,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=college_biology,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=college_computer_science,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=college_mathematics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=college_medicine,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=college_physics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=conceptual_physics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=electrical_engineering,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=elementary_mathematics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=formal_logic,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_biology,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_chemistry,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_computer_science,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_european_history,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_geography,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_government_and_politics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_macroeconomics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_mathematics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_microeconomics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_physics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_psychology,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_statistics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_us_history,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=high_school_world_history,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=human_aging,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=human_sexuality,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=international_law,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=logical_fallacies,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=machine_learning,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=management,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=marketing,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=medical_genetics,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=miscellaneous,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=moral_disputes,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=moral_scenarios,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=nutrition,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=prehistory,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=professional_accounting,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=professional_law,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=professional_psychology,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=public_relations,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=security_studies,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=sociology,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=virology,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}
"mmlu:model=text,subject=world_religions,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 4}


##### Information Retrieval #####
# Scenarios: MS Marco (Regular), MS MARCO (TREC)

# TODO: rename scenario to msmarco, track to msmarco - Issue 527
# TODO: Update valid_topk=30 based on AI21 results
# TODO: reenable after MultipleInstance refactor
# "msmarco:task=passage,model=full_functionality_text,track=regular,use_qrels_passages=True,use_topk_passages=True,valid_topk=30,num_valid_queries=200,num_train_trials=default": {status: "READY", priority: 2}
# "msmarco:task=passage,model=full_functionality_text,track=trec,use_qrels_passages=True,use_topk_passages=True,valid_topk=30,num_train_trials=default": {status: "READY", priority: 1}
# "msmarco:task=passage,model=full_functionality_text,track=regular,use_qrels_passages=False,use_topk_passages=True,valid_topk=30,num_valid_queries=200,num_train_trials=default": {status: "READY", priority: 2}
# "msmarco:task=passage,model=full_functionality_text,track=trec,use_qrels_passages=False,use_topk_passages=True,valid_topk=30,num_train_trials=default": {status: "READY", priority: 1}


##### Summarization #####
# Scenarios: XSUM, CNN/DM

"summarization_cnndm:model=text,temperature=0.3,device=cpu,num_train_trials=default": {status: "READY", priority: 1}
"summarization_xsum_sampled:model=text,temperature=0.3,device=cpu,num_train_trials=default": {status: "READY", priority: 1}


##### Sentiment Analysis #####
# Scenarios: IMDB

"imdb:model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 1}


##### (Miscellaneous) Text Classification #####
# Scenarios: RAFT

"raft:subset=ade_corpus_v2,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=banking_77,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=neurips_impact_statement_risks,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=one_stop_english,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=overruling,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=semiconductor_org_types,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=tweet_eval_hate,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=twitter_complaints,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=systematic_review_inclusion,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=tai_safety_research,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"raft:subset=terms_of_service,model=text,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}


##### Toxicity Detection #####
# Scenarios: CivilComments

"civil_comments:model=text,subject=all,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 1}
"civil_comments:model=text,subject=asian,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=atheist,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=bisexual,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"civil_comments:model=text,subject=black,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=buddhist,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=christian,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"civil_comments:model=text,subject=female,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=heterosexual,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"civil_comments:model=text,subject=hindu,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=homosexual_gay_or_lesbian,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"civil_comments:model=text,subject=intellectual_or_learning_disability,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"civil_comments:model=text,subject=jewish,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=latino,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=male,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=muslim,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"civil_comments:model=text,subject=other_disability,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=other_gender,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=other_race_or_ethnicity,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=other_religion,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=other_sexual_orientation,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}
"civil_comments:model=text,subject=physical_disability,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"civil_comments:model=text,subject=psychiatric_or_mental_illness,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"civil_comments:model=text,subject=transgender,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 2}
"civil_comments:model=text,subject=white,data_augmentation=canonical,num_train_trials=default": {status: "READY", priority: 3}


##### Component Skills and Risks #####

##### Language #####
# Scenarios: BLiMP, The Pile, ICE, WikiText-103, TwitterAAE

# We select 4 phenomena to elevate to priority 2, one per linguistic field.
# The phenomena in BLiMP are annotated belong to one of the following 4 linguistic fields:
# Morphology, Semantics, Syntax, and Syntax-Semantics
# Beyond ensuring coverage of these 4 fields, to choose the higher priority representative,
# we choose the phenomena within the field with the lowest GPT-2 performance reported (Warsadt et al., 2020).
"blimp:model=full_functionality_text,phenomenon=anaphor_agreement,num_train_trials=default": {status: "READY", priority: 3} # Morphology
"blimp:model=full_functionality_text,phenomenon=determiner_noun_agreement,num_train_trials=default": {status: "READY", priority: 3} # Morphology
"blimp:model=full_functionality_text,phenomenon=irregular_forms,num_train_trials=default": {status: "READY", priority: 2} # Morphology
"blimp:model=full_functionality_text,phenomenon=subject_verb_agreement,num_train_trials=default": {status: "READY", priority: 3} # Morphology
"blimp:model=full_functionality_text,phenomenon=quantifiers,num_train_trials=default": {status: "READY", priority: 2} # Semantics
"blimp:model=full_functionality_text,phenomenon=npi_licensing,num_train_trials=default": {status: "READY", priority: 3} # Semantics
"blimp:model=full_functionality_text,phenomenon=argument_structure,num_train_trials=default": {status: "READY", priority: 3} # Syntax
"blimp:model=full_functionality_text,phenomenon=ellipsis,num_train_trials=default": {status: "READY", priority: 3} # Syntax
"blimp:model=full_functionality_text,phenomenon=filler_gap_dependency,num_train_trials=default": {status: "READY", priority: 3} # Syntax
"blimp:model=full_functionality_text,phenomenon=island_effects,num_train_trials=default": {status: "READY", priority: 2} # Syntax
"blimp:model=full_functionality_text,phenomenon=binding,num_train_trials=default": {status: "READY", priority: 2} # Syntax-Semantics
"blimp:model=full_functionality_text,phenomenon=control_raising,num_train_trials=default": {status: "READY", priority: 3} # Syntax-Semantics

## Language modeling

"wikitext_103:model=full_functionality_text,num_train_trials=default": {status: "READY", priority: 3}

"the_pile:model=full_functionality_text,subset=ArXiv,num_train_trials=default": {status: "READY", priority: 2}
"the_pile:model=full_functionality_text,subset=BookCorpus2,num_train_trials=default": {status: "READY", priority: 2}
"the_pile:model=full_functionality_text,subset=Books3,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=DM Mathematics,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=Enron Emails,num_train_trials=default": {status: "READY", priority: 2}
"the_pile:model=full_functionality_text,subset=EuroParl,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=FreeLaw,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=Github,num_train_trials=default": {status: "READY", priority: 2}
"the_pile:model=full_functionality_text,subset=Gutenberg (PG-19),num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=HackerNews,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=NIH ExPorter,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=OpenSubtitles,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=OpenWebText2,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=PhilPapers,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=Pile-CC,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=PubMed Abstracts,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=PubMed Central,num_train_trials=default": {status: "READY", priority: 2}
"the_pile:model=full_functionality_text,subset=StackExchange,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=USPTO Backgrounds,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=Ubuntu IRC,num_train_trials=default": {status: "READY", priority: 3}
"the_pile:model=full_functionality_text,subset=Wikipedia (en),num_train_trials=default": {status: "READY", priority: 2}
"the_pile:model=full_functionality_text,subset=YoutubeSubtitles,num_train_trials=default": {status: "READY", priority: 3}

"twitter_aae:model=full_functionality_text,demographic=aa,num_train_trials=default": {status: "READY", priority: 1}
"twitter_aae:model=full_functionality_text,demographic=white,num_train_trials=default": {status: "READY", priority: 1}

"ice:model=full_functionality_text,subset=can": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ea": {status: "READY", priority: 2}
"ice:model=full_functionality_text,subset=hk": {status: "READY", priority: 2}
"ice:model=full_functionality_text,subset=ind": {status: "READY", priority: 2}
"ice:model=full_functionality_text,subset=ja": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=phi": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=sin": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=usa": {status: "READY", priority: 2}

# split by text category
"ice:model=full_functionality_text,subset=can,category=S1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=can,category=S2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=can,category=W1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=can,category=W2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ea,category=S1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ea,category=S2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ea,category=W1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ea,category=W2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=hk,category=S1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=hk,category=S2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=hk,category=W1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=hk,category=W2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ind,category=S1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ind,category=S2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ind,category=W1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ind,category=W2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ja,category=S1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ja,category=S2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ja,category=W1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=ja,category=W2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=phi,category=S1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=phi,category=S2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=phi,category=W1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=phi,category=W2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=sin,category=S1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=sin,category=S2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=sin,category=W1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=sin,category=W2": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=usa,category=W1": {status: "READY", priority: 3}
"ice:model=full_functionality_text,subset=usa,category=W2": {status: "READY", priority: 3}

# TODO: not reproducible: https://github.com/stanford-crfm/benchmarking/issues/467
# "ice:model=full_functionality_text,split=spoken,num_train_trials=default": {status: "READY", priority: 3}
# "ice:model=full_functionality_text,split=written,num_train_trials=default": {status: "READY", priority: 3}
# "ice:model=full_functionality_text,gender=female,num_train_trials=default": {status: "READY", priority: 2}
# "ice:model=full_functionality_text,gender=male,num_train_trials=default": {status: "READY", priority: 2}


##### Knowledge #####

# For WikiFact, we sampled the following 10 relation types, which cover diverse topics
# across general facts, humanities, social sciences and STEM.
"wikifact:model=text,k=5,subject=plaintiff,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=place_of_birth,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=medical_condition_treated,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=instance_of,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=part_of,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=currency,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=position_held,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=author,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=discoverer_or_inventor,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=symptoms_and_signs,num_train_trials=default": {status: "READY", priority: 2}
"wikifact:model=text,k=5,subject=applies_to_jurisdiction,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=field_of_work,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=member_of_political_party,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=native_language,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=occupation,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=employer,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=atomic_number,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=measured_physical_quantity,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=solved_by,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=number_of_processor_cores,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=file_extension,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=basic_form_of_government,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=owned_by,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=instrument,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=central_bank,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=located_in_the_administrative_territorial_entity,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=office_held_by_head_of_government,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=movement,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=genre,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=capital_of,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=named_after,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=religion,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=languages_spoken_written_or_signed,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=headquarters_location,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=defendant,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=award_received,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=country,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=creator,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=manufacturer,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=developer,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=location_of_discovery,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=twinned_administrative_body,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=office_held_by_head_of_state,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=participating_team,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=place_of_death,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=drug_or_therapy_used_for_treatment,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=genetic_association,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=statement_describes,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=repealed_by,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=record_label,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=country_of_citizenship,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=location,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=programming_language,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=subclass_of,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=continent,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=laws_applied,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=operating_system,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=head_of_state,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=subsidiary,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=capital,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=original_language_of_film_or_TV_show,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=official_language,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=overrules,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=therapeutic_area,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=language_of_work_or_name,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=position_played_on_team,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=stock_exchange,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=original_network,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=industry,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=member_of,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=shares_border_with,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=country_of_origin,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=has_part,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=diplomatic_relation,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=member_of_sports_team,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=director,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=time_of_discovery_or_invention,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=majority_opinion_by,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=head_of_government,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=educated_at,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=influenced_by,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=location_of_formation,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=electron_configuration,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=recommended_unit_of_measurement,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=composer,num_train_trials=default": {status: "READY", priority: 4}
"wikifact:model=text,k=5,subject=work_location,num_train_trials=default": {status: "READY", priority: 4}



##### Reasoning #####

## Synthetic
# TODO: had to disable these due to a refactor
#"numeracy:model=all,run_solver=True,relation_type=linear,mode=function": {status: "READY", priority: 2}
#"numeracy:model=all,run_solver=True,relation_type=plane,mode=function": {status: "READY", priority: 3}

# The DistanceMetric is slow to compute for relation_type 'parabola' and 'paraboloid', so set run_solver=False
#"numeracy:model=all,run_solver=False,relation_type=parabola,mode=function": {status: "READY", priority: 4}
#"numeracy:model=all,run_solver=False,relation_type=paraboloid,mode=function": {status: "READY", priority: 4}

"synthetic_reasoning:model=all,mode=pattern_match,num_train_trials=default": {status: "READY", priority: 2}
"synthetic_reasoning:model=all,mode=variable_substitution,num_train_trials=default": {status: "READY", priority: 2}
"synthetic_reasoning:model=all,mode=induction,num_train_trials=default": {status: "READY", priority: 2}

"synthetic_reasoning_natural:model=all,difficulty=easy,num_train_trials=default": {status: "READY", priority: 2}
"synthetic_reasoning_natural:model=all,difficulty=hard,num_train_trials=default": {status: "READY", priority: 2}

"babi_qa:model=all,task=all,num_train_trials=default": {status: "READY", priority: 2}
"babi_qa:model=all,task=1,num_train_trials=default": {status: "READY", priority: 3}
"babi_qa:model=all,task=2,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=3,num_train_trials=default": {status: "READY", priority: 2}
"babi_qa:model=all,task=4,num_train_trials=default": {status: "READY", priority: 3}
"babi_qa:model=all,task=5,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=6,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=7,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=8,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=9,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=10,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=11,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=12,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=13,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=14,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=15,num_train_trials=default": {status: "READY", priority: 2}
"babi_qa:model=all,task=16,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=17,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=18,num_train_trials=default": {status: "READY", priority: 4}
"babi_qa:model=all,task=19,num_train_trials=default": {status: "READY", priority: 2}
"babi_qa:model=all,task=20,num_train_trials=default": {status: "READY", priority: 4}

"dyck_language:model=all,num_parenthesis_pairs=2,num_train_trials=default": {status: "READY", priority: 4}
"dyck_language:model=all,num_parenthesis_pairs=3,num_train_trials=default": {status: "READY", , priority: 2}
"dyck_language:model=all,num_parenthesis_pairs=4,num_train_trials=default": {status: "READY", priority: 4}

## Real

"math:model=all,subject=number_theory,level=1,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=intermediate_algebra,level=1,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=algebra,level=1,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=prealgebra,level=1,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=geometry,level=1,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=counting_and_probability,level=1,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=precalculus,level=1,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 2}

"math:model=all,subject=number_theory,level=2,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=intermediate_algebra,level=2,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=algebra,level=2,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=prealgebra,level=2,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=geometry,level=2,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=counting_and_probability,level=2,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=precalculus,level=2,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}

"math:model=all,subject=number_theory,level=3,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=intermediate_algebra,level=3,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=algebra,level=3,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=prealgebra,level=3,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=geometry,level=3,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=counting_and_probability,level=3,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=precalculus,level=3,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}

"math:model=all,subject=number_theory,level=4,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=intermediate_algebra,level=4,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=algebra,level=4,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=prealgebra,level=4,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=geometry,level=4,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=counting_and_probability,level=4,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=precalculus,level=4,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 4}

"math:model=all,subject=number_theory,level=5,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=intermediate_algebra,level=5,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=algebra,level=5,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=prealgebra,level=5,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=geometry,level=5,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=counting_and_probability,level=5,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=precalculus,level=5,use_official_examples=True,num_train_trials=default": {status: "READY", priority: 3}

# With chain-of-thought prompting:
"math:model=all,subject=number_theory,level=1,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=intermediate_algebra,level=1,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=algebra,level=1,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=prealgebra,level=1,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=geometry,level=1,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=counting_and_probability,level=1,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 2}
"math:model=all,subject=precalculus,level=1,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 2}

"math:model=all,subject=number_theory,level=2,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=intermediate_algebra,level=2,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=algebra,level=2,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=prealgebra,level=2,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=geometry,level=2,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=counting_and_probability,level=2,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=precalculus,level=2,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}

"math:model=all,subject=number_theory,level=3,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=intermediate_algebra,level=3,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=algebra,level=3,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=prealgebra,level=3,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=geometry,level=3,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=counting_and_probability,level=3,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=precalculus,level=3,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}

"math:model=all,subject=number_theory,level=4,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=intermediate_algebra,level=4,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=algebra,level=4,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=prealgebra,level=4,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=geometry,level=4,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=counting_and_probability,level=4,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}
"math:model=all,subject=precalculus,level=4,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 4}

"math:model=all,subject=number_theory,level=5,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=intermediate_algebra,level=5,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=algebra,level=5,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=prealgebra,level=5,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=geometry,level=5,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=counting_and_probability,level=5,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}
"math:model=all,subject=precalculus,level=5,use_chain_of_thought=True,num_train_trials=default": {status: "READY", priority: 3}

"gsm:model=all,num_train_trials=default": {status: "READY", priority: 2}

# Legal reasoning
"legal_support:model=all,num_train_trials=default": {status: "READY", priority: 2}

"lsat_qa:model=all,task=all,num_train_trials=default": {status: "READY", priority: 2}
"lsat_qa:model=all,task=grouping,num_train_trials=default": {status: "READY", priority: 3}
"lsat_qa:model=all,task=ordering,num_train_trials=default": {status: "READY", priority: 3}
"lsat_qa:model=all,task=assignment,num_train_trials=default": {status: "READY", priority: 3}
"lsat_qa:model=all,task=miscellaneous,num_train_trials=default": {status: "READY", priority: 3}

# Data processing

"entity_matching:model=text,dataset=Beer,num_train_trials=default": {status: "READY", priority: 2}
"entity_matching:model=text,dataset=Abt_Buy,num_train_trials=default": {status: "READY", priority: 2}
"entity_matching:model=text,dataset=Dirty_iTunes_Amazon,num_train_trials=default": {status: "READY", priority: 2}

"entity_data_imputation:model=text,dataset=Buy,num_train_trials=default": {status: "READY", priority: 2}
"entity_data_imputation:model=text,dataset=Restaurant,num_train_trials=default": {status: "READY", priority: 2}

# Code
"code:model=code,dataset=humaneval,num_train_trials=default": {status: "READY", priority: 1}
"code:model=code,dataset=apps,timeout=3,num_train_trials=default": {status: "READY", priority: 1}


##### Harms #####

## Copyright

# Randomly sampled instances from the original BooksCorpus.
# We expect data here to be less repeated in the pretraining corpus. This approximates the average case.
"copyright:model=text,datatag=n_books_1000-extractions_per_book_1-prefix_length_125,num_train_trials=default": {status: "READY", priority: 1}

# We expect data here to be repeated more in the pretraining corpus. This approximates the worst case.
"copyright:model=text,datatag=popular_books-prefix_length_125.json,num_train_trials=default": {status: "READY", priority: 1}

# Large and small codex models.
"copyright:model=code,datatag=prompt_num_line_1-min_lines_20.json,num_train_trials=default": {status: "READY", priority: 2}
"copyright:model=code,datatag=prompt_num_line_5-min_lines_20.json,num_train_trials=default": {status: "READY", priority: 3}
"copyright:model=code,datatag=prompt_num_line_10-min_lines_20.json,num_train_trials=default": {status: "READY", priority: 2}

## Disinformation

"disinformation:model=text,capability=reiteration,topic=climate,num_train_trials=default": {status: "READY", priority: 1}
"disinformation:model=text,capability=reiteration,topic=covid,num_train_trials=default": {status: "READY", priority: 1}
"disinformation:model=text,capability=wedging,num_train_trials=default": {status: "READY", priority: 1}

## Bias

"bbq:model=text,subject=all,num_train_trials=default": {status: "READY", priority: 2}
"bbq:model=text,subject=age,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=disability_status,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=gender_identity,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=nationality,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=physical_appearance,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=race_ethnicity,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=race_x_SES,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=race_x_gender,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=religion,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=SES,num_train_trials=default": {status: "READY", priority: 3}
"bbq:model=text,subject=sexual_orientation,num_train_trials=default": {status: "READY", priority: 3}

## Toxicity

"real_toxicity_prompts:model=text,num_train_trials=default": {status: "READY", priority: 2}

"bold:model=text,subject=all,num_train_trials=default": {status: "READY", priority: 2}
"bold:model=text,subject=gender,num_train_trials=default": {status: "READY", priority: 3}
"bold:model=text,subject=political_ideology,num_train_trials=default": {status: "READY", priority: 3}
"bold:model=text,subject=profession,num_train_trials=default": {status: "READY", priority: 3}
"bold:model=text,subject=race,num_train_trials=default": {status: "READY", priority: 3}
"bold:model=text,subject=religious_ideology,num_train_trials=default": {status: "READY", priority: 3}


##### Efficiency #####

"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=256,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=256,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=256,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=256,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=256,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=256,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=256,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=256,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=256,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=256,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=256,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=256,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=256,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=256,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=512,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=512,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=512,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=512,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=512,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=512,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=512,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=512,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=512,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=512,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=512,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=512,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=512,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=512,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1024,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1024,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1024,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1024,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1024,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1024,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1024,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1024,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1024,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1024,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1024,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1024,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1024,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1024,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1536,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1536,num_output_tokens=1,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1536,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1536,num_output_tokens=2,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1536,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1536,num_output_tokens=4,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1536,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1536,num_output_tokens=8,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1536,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1536,num_output_tokens=16,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1536,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1536,num_output_tokens=32,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=gpt2_tokenizer,tokenizer=huggingface/gpt2,num_prompt_tokens=1536,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}
"synthetic_efficiency:model=ai21_tokenizer,tokenizer=ai21/j1,num_prompt_tokens=1536,num_output_tokens=64,num_train_trials=default": {status: "READY", priority: 1}

##### Robustness #####

## Contrast sets (these are separate runs since we will only consider Instances that have contrast sets
"boolq:model=text,only_contrast=True,data_augmentation=contrast_sets,num_train_trials=default": {status: "READY", priority: 2}
"imdb:model=text,only_contrast=True,data_augmentation=contrast_sets,num_train_trials=default": {status: "READY", priority: 2}
