# MMLU subjects used for InteractiveQA. Run:
# benchmark-present --local --priority 1 --suite interactive_qa_mmlu  --num-threads 1 --num-train-trials 3
# --conf-path src/benchmark/presentation/run_specs_interactive_qa.conf --max-eval-instances 10

entries: [
  {description: "interactive_qa_mmlu:model=openai/text-davinci-001,subject=college_chemistry", priority: 1}
  {description: "interactive_qa_mmlu:model=openai/text-davinci-001,subject=global_facts", priority: 1}
  {description: "interactive_qa_mmlu:model=openai/text-davinci-001,subject=miscellaneous", priority: 1}
  {description: "interactive_qa_mmlu:model=openai/text-davinci-001,subject=nutrition", priority: 1}
  {description: "interactive_qa_mmlu:model=openai/text-davinci-001,subject=us_foreign_policy", priority: 1}
]
